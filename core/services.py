
import os
from utils import measure_time
from utils import logger
from cli import model

@measure_time
def filter_articles_with_faiss(
    articles,
    keywords,
    threshold=0.7,
    index_path="keywords_index.faiss",
    show_progress=False,
):
    """
    Filtre les articles par similaritÃ© sÃ©mantique avec les mots-clÃ©s.
    :param articles: Liste de dicts avec 'title' et 'summary'
    :param keywords: Liste de mots-clÃ©s
    :param threshold: Seuil de similaritÃ© (0 Ã  1)
    :return: Articles filtrÃ©s
    """
    import faiss

    logger.info(f"Filtrage sÃ©mantique avec les mots-clÃ©s {keywords}")
    logger.info(f"Filtrage sÃ©mantique avec seuil {threshold}...")

    @measure_time
    def get_or_create_index(keywords, model, index_path):
        if os.path.exists(index_path):
            logger.info("ğŸ” Chargement de l'index FAISS existant...")
            return faiss.read_index(index_path)
        else:
            logger.info("ğŸ”§ CrÃ©ation d'un nouvel index FAISS...")
            keyword_embeddings = model.encode(
                keywords, convert_to_tensor=True, show_progress_bar=show_progress
            )
            keyword_embeddings = keyword_embeddings.cpu().numpy()
            faiss.normalize_L2(keyword_embeddings)
            index = faiss.IndexFlatIP(keyword_embeddings.shape[1])
            index.add(keyword_embeddings)
            faiss.write_index(index, index_path)
            return index

    # CrÃ©er un index FAISS pour le produit scalaire (similaritÃ© cosinus)
    index = get_or_create_index(keywords, model, index_path)

    filtered = []
    for article in articles:
        text = f"{article['title']} {article['summary']}".strip()
        if not text:
            continue  # Sauter les articles sans contenu

        article_embedding = model.encode(
            [text], convert_to_tensor=True, show_progress_bar=False
        )
        article_embedding = article_embedding.cpu().numpy()
        faiss.normalize_L2(article_embedding)  # Normaliser l'embedding de l'article

        # Recherche
        similarities, indices = index.search(article_embedding, k=len(keywords))
        max_similarity = similarities[0].max()  # La similaritÃ© est dÃ©jÃ  entre 0 et 1

        if max_similarity >= threshold:
            matched_keywords = [
                keywords[i] for i in indices[0] if similarities[0][i] >= threshold
            ]
            logger.info(
                f"âœ… Article retenu (sim={max_similarity:.2f}, mots-clÃ©s: {matched_keywords}): {article['title']} {article['link']}"
            )
            filtered.append(article)

    logger.info(
        f"ğŸ“Š {len(filtered)}/{len(articles)} articles aprÃ¨s filtrage sÃ©mantique (seuil={threshold})"
    )
    return filtered
